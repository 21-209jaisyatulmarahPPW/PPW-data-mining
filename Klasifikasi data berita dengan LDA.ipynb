{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"12tI6srb9fir3V5TJTokPc62JfhzaiG-Z","timestamp":1760461094344}],"cell_execution_strategy":"setup","mount_file_id":"12tI6srb9fir3V5TJTokPc62JfhzaiG-Z","authorship_tag":"ABX9TyMpk8VJFVPhjbyhW+EWMiRE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R1KAJ-gomJ-i"},"outputs":[],"source":["# --- 1. Import Library ---\n","import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report, accuracy_score\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","# --- 2. Load Dataset ---\n","df = pd.read_csv(\"/content/drive/MyDrive/PPW/artikel_medium_multitopik_rss.csv\")  # sesuaikan path di Colab\n","print(\"Jumlah data:\", len(df))\n","print(df.head())\n","\n","# --- 3. Preprocessing ---\n","stop_words = set(stopwords.words('english'))\n","\n","def clean_text(text):\n","    text = str(text).lower()  # lowercase\n","    text = re.sub(r'[^a-z\\s]', '', text)  # hapus karakter non-huruf\n","    tokens = [word for word in text.split() if word not in stop_words and len(word) > 2]\n","    return \" \".join(tokens)\n","\n","df[\"clean_text\"] = df[\"isi\"].apply(clean_text)\n","\n","# --- 4. Split Data ---\n","X_train, X_test, y_train, y_test = train_test_split(df[\"clean_text\"], df[\"kategori\"],\n","                                                    test_size=0.2, random_state=42, stratify=df[\"kategori\"])\n","\n","# --- 5. Ubah ke representasi count untuk LDA ---\n","vectorizer = CountVectorizer(max_features=3000)\n","X_train_counts = vectorizer.fit_transform(X_train)\n","X_test_counts = vectorizer.transform(X_test)\n","\n","# --- 6. Latent Dirichlet Allocation (LDA) untuk ekstraksi fitur ---\n","n_topics = 10  # jumlah topik tersembunyi\n","lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n","X_train_lda = lda.fit_transform(X_train_counts)\n","X_test_lda = lda.transform(X_test_counts)\n","\n","print(\"Dimensi hasil LDA:\", X_train_lda.shape)\n","\n","# --- 7. Klasifikasi (Naive Bayes) ---\n","model = MultinomialNB()\n","model.fit(X_train_lda, y_train)\n","y_pred = model.predict(X_test_lda)\n","\n","# --- 8. Evaluasi ---\n","print(\"\\n=== HASIL EVALUASI ===\")\n","print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# --- 9. Contoh Prediksi Baru ---\n","contoh = [\"AI helps doctors detect diseases early\"]\n","contoh_counts = vectorizer.transform(contoh)\n","contoh_lda = lda.transform(contoh_counts)\n","prediksi = model.predict(contoh_lda)\n","print(\"\\nContoh Prediksi:\", prediksi[0])\n"]}]}